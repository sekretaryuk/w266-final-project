{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Lost in Translation: Computational Approach to Linear A Decryption with LSTM and Transformer Models\n","### *Team: Steven Lu, Georgiy Sekretaryuk, Oluwafemi*"],"metadata":{"id":"ns329APPQlk1"}},{"cell_type":"markdown","source":["## OUTLINE\n","\n","Part 1 Goals:\n","- replicate NeuroDecipher LSTM model with Linear B\n","- apply NeuroDecipher NLP approaches in a transformer model\n","- test different pre-training techniques and parameters to see how it influences the result\n","\n","Part 2 Goals:\n","\n","...TBD after Nov 13\n","- Work with Linear A here"],"metadata":{"id":"68cUlXO-Q1PE"}},{"cell_type":"markdown","source":["## IMPORTS\n","\n","Import the necessary libraries for the project and define any additional configurations."],"metadata":{"id":"A95gI6tYhP19"}},{"cell_type":"code","source":["# IMPORT THE LIBRARIES HERE\n","import os\n","import shutil\n","import sys"],"metadata":{"id":"T3eQrjVocsjt","executionInfo":{"status":"ok","timestamp":1699757766844,"user_tz":420,"elapsed":3,"user":{"displayName":"Georgiy Sekretaryuk","userId":"10527185079278825442"}}},"execution_count":49,"outputs":[]},{"cell_type":"code","source":["#setup for GDrive\n","# #@title SELECT USER to mount the data drive according to its path in your drive\n","# USER = 'Georgiy' #@param ['Georgiy', 'Steven', 'Oluwafemi']\n","\n","# #@title Mount GDrive\n","# from google.colab import drive\n","# drive.mount('/content/drive', force_remount=True)\n","# #remove cache\n","# !rm -rf \"/content/drive/MyDrive/NLP_266/__pycache__\"\n","\n","# #@title Set PATH to /data/ folder\n","# PATHS = {}\n","# PATHS['Georgiy'] = \"/content/drive/MyDrive/NLP_266\"\n","# PATHS['Steven'] = \"/content/drive/Shareddrives/PathForSteven\"  # Replace with the actual path\n","# PATHS['Oluwafemi'] = \"/content/drive/Shareddrives/PathForOluwafemi\"  # Replace with the actual path\n","# PATH = PATHS[USER]\n","\n","# if PATH == \"\":\n","#     raise ValueError(\"Enter your path to the shared data folder.\\nIt should start with 'content/drive/...' and end with '.../281 Final Project/data/\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":471},"id":"2ovQjQW5V2Zn","executionInfo":{"status":"error","timestamp":1699758109643,"user_tz":420,"elapsed":2973,"user":{"displayName":"Georgiy Sekretaryuk","userId":"10527185079278825442"}},"outputId":"c97f0b0e-2170-4cb8-bb7b-fee6940a98be"},"execution_count":55,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/MyDrive/NLP_266\n"," lineara_workfile.ipynb         testing_module.py\n","'Setting Up the Problem.gdoc'  'W266 Project Proposal.gdoc'\n"]},{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-55-662b3cfbb254>\u001b[0m in \u001b[0;36m<cell line: 27>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mspec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspec_from_file_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"testing_module\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"/content/drive/MyDrive/NLP_266/testing_module.py\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mfoo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule_from_spec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexec_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfoo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0mfoo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n","\u001b[0;32m/content/drive/MyDrive/NLP_266/testing_module.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m{\u001b[0m\u001b[0;34m\"nbformat\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"nbformat_minor\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"metadata\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"colab\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"provenance\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"mount_file_id\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"1FcMWtkKct1bxvcbjqUXvgJPSfWbMF6IQ\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"authorship_tag\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"ABX9TyPnBHhoB1XVrTBQtB8w6ald\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"kernelspec\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"name\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"python3\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"display_name\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"Python 3\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"language_info\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"name\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"python\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"cells\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"cell_type\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"code\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"execution_count\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"metadata\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"id\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"C7eWTq0dUjIl\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"executionInfo\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"status\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"ok\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"timestamp\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1699757990750\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"user_tz\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m420\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"elapsed\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"user\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"displayName\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[...\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'null' is not defined"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nD6I0mNzQjqj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1699754237593,"user_tz":420,"elapsed":37580,"user":{"displayName":"Georgiy Sekretaryuk","userId":"10527185079278825442"}},"outputId":"354b6e8f-6481-41ba-f529-f1d50cd7ae59"},"outputs":[{"output_type":"stream","name":"stdout","text":["The folder 'NeuroDecipher' has been removed.\n","Cloning into 'NeuroDecipher'...\n","remote: Enumerating objects: 210, done.\u001b[K\n","remote: Counting objects: 100% (34/34), done.\u001b[K\n","remote: Compressing objects: 100% (27/27), done.\u001b[K\n","remote: Total 210 (delta 14), reused 18 (delta 7), pack-reused 176\u001b[K\n","Receiving objects: 100% (210/210), 259.28 KiB | 6.82 MiB/s, done.\n","Resolving deltas: 100% (94/94), done.\n","fatal: not a git repository (or any of the parent directories): .git\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu118)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.16.0+cu118)\n","Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.1.0+cu118)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.23.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.31.0)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2023.7.22)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n","Requirement already satisfied: cython in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (3.0.5)\n","Requirement already satisfied: ortools in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (9.7.2996)\n","Requirement already satisfied: cvxopt in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (1.3.2)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (1.5.3)\n","Requirement already satisfied: prettytable in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (3.9.0)\n","Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (2.14.0)\n","Requirement already satisfied: treelib in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (1.7.0)\n","Requirement already satisfied: enlighten in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (1.12.2)\n","Requirement already satisfied: pytrie in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (0.4.0)\n","Requirement already satisfied: colorlog in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (6.7.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 11)) (1.23.5)\n","Requirement already satisfied: absl-py>=0.13 in /usr/local/lib/python3.10/dist-packages (from ortools->-r requirements.txt (line 2)) (1.4.0)\n","Requirement already satisfied: protobuf>=4.23.3 in /usr/local/lib/python3.10/dist-packages (from ortools->-r requirements.txt (line 2)) (4.25.0)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->-r requirements.txt (line 4)) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->-r requirements.txt (line 4)) (2023.3.post1)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prettytable->-r requirements.txt (line 5)) (0.2.9)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r requirements.txt (line 6)) (1.6.3)\n","Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r requirements.txt (line 6)) (23.5.26)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r requirements.txt (line 6)) (0.5.4)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r requirements.txt (line 6)) (0.2.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r requirements.txt (line 6)) (3.9.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r requirements.txt (line 6)) (16.0.6)\n","Requirement already satisfied: ml-dtypes==0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r requirements.txt (line 6)) (0.2.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r requirements.txt (line 6)) (3.3.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r requirements.txt (line 6)) (23.2)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r requirements.txt (line 6)) (67.7.2)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r requirements.txt (line 6)) (1.16.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r requirements.txt (line 6)) (2.3.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r requirements.txt (line 6)) (4.5.0)\n","Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r requirements.txt (line 6)) (1.14.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r requirements.txt (line 6)) (0.34.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r requirements.txt (line 6)) (1.59.2)\n","Requirement already satisfied: tensorboard<2.15,>=2.14 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r requirements.txt (line 6)) (2.14.1)\n","Requirement already satisfied: tensorflow-estimator<2.15,>=2.14.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r requirements.txt (line 6)) (2.14.0)\n","Requirement already satisfied: keras<2.15,>=2.14.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r requirements.txt (line 6)) (2.14.0)\n","Requirement already satisfied: blessed>=1.17.7 in /usr/local/lib/python3.10/dist-packages (from enlighten->-r requirements.txt (line 8)) (1.20.0)\n","Requirement already satisfied: prefixed>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from enlighten->-r requirements.txt (line 8)) (0.7.0)\n","Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.10/dist-packages (from pytrie->-r requirements.txt (line 9)) (2.4.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow->-r requirements.txt (line 6)) (0.41.3)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow->-r requirements.txt (line 6)) (2.17.3)\n","Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow->-r requirements.txt (line 6)) (1.0.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow->-r requirements.txt (line 6)) (3.5.1)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow->-r requirements.txt (line 6)) (2.31.0)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow->-r requirements.txt (line 6)) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow->-r requirements.txt (line 6)) (3.0.1)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow->-r requirements.txt (line 6)) (5.3.2)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow->-r requirements.txt (line 6)) (0.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow->-r requirements.txt (line 6)) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow->-r requirements.txt (line 6)) (1.3.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow->-r requirements.txt (line 6)) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow->-r requirements.txt (line 6)) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow->-r requirements.txt (line 6)) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow->-r requirements.txt (line 6)) (2023.7.22)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow->-r requirements.txt (line 6)) (2.1.3)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow->-r requirements.txt (line 6)) (0.5.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow->-r requirements.txt (line 6)) (3.2.2)\n","Processing /content/NeuroDecipher\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: NeuroDecipher\n","  Building wheel for NeuroDecipher (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for NeuroDecipher: filename=NeuroDecipher-0.1-py3-none-any.whl size=30194 sha256=d7d212996ec7f490ac354fcbb07d37294fcd421095f9713a3d2bd888a6380d5a\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-_o498ryn/wheels/e5/f5/9f/0dbc7e11ed8d283a2b89a1b8cf996c58bedf43bfeb1f6b979e\n","Successfully built NeuroDecipher\n","Installing collected packages: NeuroDecipher\n","  Attempting uninstall: NeuroDecipher\n","    Found existing installation: NeuroDecipher 0.1\n","    Uninstalling NeuroDecipher-0.1:\n","      Successfully uninstalled NeuroDecipher-0.1\n","Successfully installed NeuroDecipher-0.1\n","Processing /content/NeuroDecipher/editdistance\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: editdistance\n","  Building wheel for editdistance (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for editdistance: filename=editdistance-0.5.2-cp310-cp310-linux_x86_64.whl size=414208 sha256=eb60f194fe5377cdfe751503603274f38444253407cadc8d28708a26a9610409\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-3_4m4ktq/wheels/76/d8/68/0dd890cc8ed9c9d638efa72643227866683750de0d340feb41\n","Successfully built editdistance\n","Installing collected packages: editdistance\n","  Attempting uninstall: editdistance\n","    Found existing installation: editdistance 0.5.2\n","    Uninstalling editdistance-0.5.2:\n","      Successfully uninstalled editdistance-0.5.2\n","Successfully installed editdistance-0.5.2\n","\u001b[31mERROR: Directory '.' is not installable. Neither 'setup.py' nor 'pyproject.toml' found.\u001b[0m\u001b[31m\n","\u001b[0m\u001b[31mERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'\u001b[0m\u001b[31m\n","\u001b[0m"]}],"source":["# Import Lin B from NeuroDecipher https://github.com/j-luo93/NeuroDecipher\n","\n","folder_path = 'NeuroDecipher'\n","\n","if os.path.exists(folder_path):\n","    shutil.rmtree(folder_path)\n","    print(f\"The folder '{folder_path}' has been removed.\")\n","else:\n","    print(f\"The folder '{folder_path}' does not exist.\")\n","\n","!git clone https://github.com/j-luo93/NeuroDecipher\n","!git submodule init && git submodule update\n","!pip install torch torchvision torchaudio\n","!cd NeuroDecipher && pip install -r requirements.txt\n","!cd NeuroDecipher && pip install .\n","!cd NeuroDecipher/arglib && ls\n","!cd NeuroDecipher/editdistance && pip install .\n","!cd NeuroDecipher/arglib && pip install .\n","!cd NeuroDecipher/dev_misc && pip install -r requirements.txt\n","!cd NeuroDecipher/dev_misc && pip install ."]},{"cell_type":"code","source":["!ls\n","\n","print('-----VIEWING NEURODECIPHER FOLDER TREE-----')\n","!cd NeuroDecipher && ls\n","!cd NeuroDecipher/arglib && ls\n","!cd NeuroDecipher/dev_misc && ls\n","# !cd NeuroDecipher/nd/dataset && python3 cognate.py\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h7qeGDtDJOWA","executionInfo":{"status":"ok","timestamp":1699755104566,"user_tz":420,"elapsed":880,"user":{"displayName":"Georgiy Sekretaryuk","userId":"10527185079278825442"}},"outputId":"4a42d134-4774-45f4-e8d8-1d1f42fa893f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["NeuroDecipher\n","-----VIEWING NEURODECIPHER FOLDER TREE-----\n","arglib\tdata\t  editdistance\tNeuroDecipher.egg-info\tREADME.md\t  setup.py\n","build\tdev_misc  nd\t\tnotebooks\t\trequirements.txt\n"]}]},{"cell_type":"markdown","source":["## LOAD THE DATA\n","\n","Load the data from https://github.com/j-luo93/NeuroDecipher.\n","\n","Each .cog file is essentially a tsv file, where each column corresponds to the words in one language. Words in the same row are considered cognates. If for one word, there is no corresponding cognate in another language, _ is used to fill the cell. If multiple cognates are available for the same word, '|' is used to separate them.\n"],"metadata":{"id":"jvdwnoAuQ7qi"}},{"cell_type":"code","source":[],"metadata":{"id":"pms31bkmRAHd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## EXPLORATORY DATA ANALYSIS\n","\n","Analyze the dataset features.\n"],"metadata":{"id":"Gn1-3Fg_Xyws"}},{"cell_type":"code","source":[],"metadata":{"id":"HdD7NquyYRzk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## PRE-TRAINING & DATA MODIFICATION\n","\n","- Feature engineering here\n","- Features tbd\n","\n"],"metadata":{"id":"dg7KzeerYJdV"}},{"cell_type":"code","source":[],"metadata":{"id":"DlKUCwmpX5zR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## MODEL ARCHITECTURE\n","\n","- Identify baseline model\n","- Test other Seq2seq models\n","  - Transformer model - our own?\n","  - Or can we modify BERT/another model and train it too?"],"metadata":{"id":"Hcpc27jJX7JU"}},{"cell_type":"code","source":["\n"],"metadata":{"id":"sUxpeJLjX89Y"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## TRAINING\n","\n","- Train the model"],"metadata":{"id":"_pjRsqtmZUfW"}},{"cell_type":"code","source":["\n"],"metadata":{"id":"SLn_2sABZZ7j"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## EVALUATION\n","\n","- The primary goal metric is accuracy as compared to NeuroDecipher"],"metadata":{"id":"KCwEcUksZCCv"}},{"cell_type":"code","source":[],"metadata":{"id":"4fs1bKF0ZJJp"},"execution_count":null,"outputs":[]}]}