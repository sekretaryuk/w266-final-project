{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ns329APPQlk1"
      },
      "source": [
        "# Lost in Translation: Computational Approach to Linear A Decryption with LSTM and Transformer Models\n",
        "### *Team: Steven Lu, Georgiy Sekretaryuk, Oluwafemi*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68cUlXO-Q1PE"
      },
      "source": [
        "## OUTLINE\n",
        "\n",
        "Part 1 Goals:\n",
        "- replicate NeuroDecipher LSTM model with Linear B\n",
        "- apply NeuroDecipher NLP approaches in a transformer model\n",
        "- test different pre-training techniques and parameters to see how it influences the result\n",
        "\n",
        "Part 2 Goals:\n",
        "\n",
        "...TBD after Nov 13\n",
        "- Work with Linear A here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A95gI6tYhP19"
      },
      "source": [
        "## IMPORTS\n",
        "\n",
        "Import the necessary libraries for the project and define any additional configurations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T3eQrjVocsjt",
        "outputId": "5f007507-1e9a-4379-cbd2-aa95e3baca43"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /opt/homebrew/lib/python3.10/site-packages (4.35.2)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /opt/homebrew/lib/python3.10/site-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /opt/homebrew/lib/python3.10/site-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /opt/homebrew/lib/python3.10/site-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /opt/homebrew/lib/python3.10/site-packages (from transformers) (2023.10.3)\n",
            "Requirement already satisfied: requests in /opt/homebrew/lib/python3.10/site-packages (from transformers) (2.28.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /opt/homebrew/lib/python3.10/site-packages (from transformers) (1.26.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /opt/homebrew/lib/python3.10/site-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /opt/homebrew/lib/python3.10/site-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /opt/homebrew/lib/python3.10/site-packages (from transformers) (0.19.4)\n",
            "Requirement already satisfied: filelock in /opt/homebrew/lib/python3.10/site-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /opt/homebrew/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/homebrew/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.8.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/homebrew/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/homebrew/lib/python3.10/site-packages (from requests->transformers) (1.26.13)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/homebrew/lib/python3.10/site-packages (from requests->transformers) (2.1.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/lib/python3.10/site-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/lib/python3.10/site-packages (from requests->transformers) (2022.12.7)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.10 -m pip install --upgrade pip\u001b[0m\n",
            "Requirement already satisfied: torch in /opt/homebrew/lib/python3.10/site-packages (2.1.1)\n",
            "Requirement already satisfied: jinja2 in /opt/homebrew/lib/python3.10/site-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: networkx in /opt/homebrew/lib/python3.10/site-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: sympy in /opt/homebrew/lib/python3.10/site-packages (from torch) (1.12)\n",
            "Requirement already satisfied: typing-extensions in /opt/homebrew/lib/python3.10/site-packages (from torch) (4.8.0)\n",
            "Requirement already satisfied: filelock in /opt/homebrew/lib/python3.10/site-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: fsspec in /opt/homebrew/lib/python3.10/site-packages (from torch) (2023.10.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /opt/homebrew/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /opt/homebrew/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.10 -m pip install --upgrade pip\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/homebrew/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "# IMPORT THE LIBRARIES HERE\n",
        "!pip install transformers\n",
        "!pip install torch\n",
        "import os\n",
        "import shutil\n",
        "import sys\n",
        "import pandas as pd\n",
        "from transformers import BertTokenizer, BertModel, BertConfig\n",
        "import torch.nn as nn\n",
        "rom torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "from torch.optim import Adam\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ovQjQW5V2Zn"
      },
      "outputs": [],
      "source": [
        "#setup for GDrive\n",
        "# #@title SELECT USER to mount the data drive according to its path in your drive\n",
        "# USER = 'Georgiy' #@param ['Georgiy', 'Steven', 'Oluwafemi']\n",
        "\n",
        "# #@title Mount GDrive\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive', force_remount=True)\n",
        "# #remove cache\n",
        "# !rm -rf \"/content/drive/MyDrive/NLP_266/__pycache__\"\n",
        "\n",
        "# #@title Set PATH to /data/ folder\n",
        "# PATHS = {}\n",
        "# PATHS['Georgiy'] = \"/content/drive/MyDrive/NLP_266\"\n",
        "# PATHS['Steven'] = \"/content/drive/Shareddrives/PathForSteven\"  # Replace with the actual path\n",
        "# PATHS['Oluwafemi'] = \"/content/drive/Shareddrives/PathForOluwafemi\"  # Replace with the actual path\n",
        "# PATH = PATHS[USER]\n",
        "\n",
        "# if PATH == \"\":\n",
        "#     raise ValueError(\"Enter your path to the shared data folder.\\nIt should start with 'content/drive/...' and end with '.../281 Final Project/data/\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nD6I0mNzQjqj"
      },
      "outputs": [],
      "source": [
        "# # Import Lin B from NeuroDecipher https://github.com/j-luo93/NeuroDecipher\n",
        "#only run this if the NeuroDecipher folder is empty\n",
        "# folder_path = 'NeuroDecipher'\n",
        "\n",
        "# if os.path.exists(folder_path):\n",
        "#    shutil.rmtree(folder_path)\n",
        "#    print(f\"The folder '{folder_path}' has been removed.\")\n",
        "# else:\n",
        "#    print(f\"The folder '{folder_path}' does not exist.\")\n",
        "\n",
        "# !git clone https://github.com/j-luo93/NeuroDecipher\n",
        "# !git submodule init && git submodule update\n",
        "# !pip install torch torchvision torchaudio\n",
        "# !cd NeuroDecipher && pip install -r requirements.txt\n",
        "# !cd NeuroDecipher && pip install .\n",
        "# !cd NeuroDecipher/arglib && ls\n",
        "# !cd NeuroDecipher/editdistance && pip install .\n",
        "# !cd NeuroDecipher/arglib && pip install .\n",
        "# !cd NeuroDecipher/dev_misc && pip install -r requirements.txt\n",
        "# !cd NeuroDecipher/dev_misc && pip install ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvdwnoAuQ7qi"
      },
      "source": [
        "## LOAD THE DATA\n",
        "\n",
        "Load the data from https://github.com/j-luo93/NeuroDecipher.\n",
        "\n",
        "Each .cog file is essentially a tsv file, where each column corresponds to the words in one language. Words in the same row are considered cognates. If for one word, there is no corresponding cognate in another language, _ is used to fill the cell. If multiple cognates are available for the same word, '|' is used to separate them.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pms31bkmRAHd",
        "outputId": "31fe6d17-33ce-4c67-95b3-f6956a0d691f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded Linear B Cognates before modifications:\n",
            "     linear_b              greek\n",
            "0      ğ€€ğ€ğ€ªğ€¦ğ€²          Î±ÎµÎ»Î¹Ï€Î¿Ï„Î±Ï‚\n",
            "1       ğ€€ğ€ğ€´ğ€µ     Î±ÎµÎ¸Î¹ÏƒÏ„Î¿Ï‚|ÎµÎ¸Î¹Î¶Ï‰\n",
            "2       ğ€€ğ€…ğ€”ğ€ƒ      Î±Î´Î±Î¼Î±Î¿|Î±Î´Î±Î¼Î±Ï‚\n",
            "3       ğ€€ğ€…ğ€•ğ€¸  Î±Î´Î±Î¼ÎµfÎµÎ¹Ï‚|Î±Î´Î±Î¼ÎµÏ…Ï‚\n",
            "4      ğ€€ğ€…ğ€¨ğ€´ğ€          Î±Î´ÏÎ±ÏƒÏ„Î¹Î¿Ï‚\n",
            "..       ...                ...\n",
            "914     ğ†ğ€¯ğ€Šğ€’          Ï†Ï…ÏƒÎ¹Î±ÏÏ‡Î¿Ï‚\n",
            "915       ğ†ğ€³              Ï†Ï…Ï„ÎµÏ\n",
            "916     ğ†ğ€³ğ€ªğ€Š            Ï†Ï…Ï„ÎµÏÎ¹Î±\n",
            "917   ğ†ğˆğ€€ğ€ğ€©ğ€„       Ï†Ï…Î»Î¹Î±Ï‚Î±Î³ÏÎµÏ…Ï‚\n",
            "918       ğ‡ğ€œ             Ï†Ï„ÎµÎ½Î¿Î¹\n",
            "\n",
            "[919 rows x 2 columns]\n",
            "Loaded Linear B Names before modifications:\n",
            "     linear_b              greek\n",
            "0      ğ€€ğ€ğ€ªğ€¦ğ€²          Î±ÎµÎ»Î¹Ï€Î¿Ï„Î±Ï‚\n",
            "1       ğ€€ğ€ğ€´ğ€µ                  _\n",
            "2       ğ€€ğ€…ğ€”ğ€ƒ      Î±Î´Î±Î¼Î±Î¿|Î±Î´Î±Î¼Î±Ï‚\n",
            "3       ğ€€ğ€…ğ€•ğ€¸  Î±Î´Î±Î¼ÎµfÎµÎ¹Ï‚|Î±Î´Î±Î¼ÎµÏ…Ï‚\n",
            "4      ğ€€ğ€…ğ€¨ğ€´ğ€          Î±Î´ÏÎ±ÏƒÏ„Î¹Î¿Ï‚\n",
            "..       ...                ...\n",
            "914     ğ†ğ€¯ğ€Šğ€’          Ï†Ï…ÏƒÎ¹Î±ÏÏ‡Î¿Ï‚\n",
            "915       ğ†ğ€³                  _\n",
            "916     ğ†ğ€³ğ€ªğ€Š                  _\n",
            "917   ğ†ğˆğ€€ğ€ğ€©ğ€„       Ï†Ï…Î»Î¹Î±Ï‚Î±Î³ÏÎµÏ…Ï‚\n",
            "918       ğ‡ğ€œ                  _\n",
            "\n",
            "[919 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "# Load the data into a pandas DataFrame\n",
        "file_path = 'NeuroDecipher/data/linear_b-greek.cog'\n",
        "file_path_names = 'NeuroDecipher/data/linear_b-greek.names.cog'\n",
        "data_linearb = pd.read_csv(file_path, sep='\\t', header=0)\n",
        "data_linearb_names = pd.read_csv(file_path_names, sep='\\t', header=0)\n",
        "\n",
        "print('Loaded Linear B Cognates before modifications:\\n', data_linearb)\n",
        "print('Loaded Linear B Names before modifications:\\n', data_linearb_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dg7KzeerYJdV"
      },
      "source": [
        "## DATA MODIFICATION\n",
        "\n",
        "- Do we split the data into individual letters?\n",
        "\n",
        "- INstead of columns for cog 1 / cog 2, turn it into rows -> increases dataset size\n",
        "- turn empty rows into test/train\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HdD7NquyYRzk",
        "outputId": "66abc283-72b0-4b91-c410-bb249ecf938f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  linear_b     greek_original greek_cog_1 greek_cog_2\n",
            "0    ğ€€ğ€ğ€ªğ€¦ğ€²          Î±ÎµÎ»Î¹Ï€Î¿Ï„Î±Ï‚   Î±ÎµÎ»Î¹Ï€Î¿Ï„Î±Ï‚            \n",
            "1     ğ€€ğ€ğ€´ğ€µ     Î±ÎµÎ¸Î¹ÏƒÏ„Î¿Ï‚|ÎµÎ¸Î¹Î¶Ï‰    Î±ÎµÎ¸Î¹ÏƒÏ„Î¿Ï‚       ÎµÎ¸Î¹Î¶Ï‰\n",
            "2     ğ€€ğ€…ğ€”ğ€ƒ      Î±Î´Î±Î¼Î±Î¿|Î±Î´Î±Î¼Î±Ï‚      Î±Î´Î±Î¼Î±Î¿      Î±Î´Î±Î¼Î±Ï‚\n",
            "3     ğ€€ğ€…ğ€•ğ€¸  Î±Î´Î±Î¼ÎµfÎµÎ¹Ï‚|Î±Î´Î±Î¼ÎµÏ…Ï‚   Î±Î´Î±Î¼ÎµfÎµÎ¹Ï‚     Î±Î´Î±Î¼ÎµÏ…Ï‚\n",
            "4    ğ€€ğ€…ğ€¨ğ€´ğ€          Î±Î´ÏÎ±ÏƒÏ„Î¹Î¿Ï‚   Î±Î´ÏÎ±ÏƒÏ„Î¹Î¿Ï‚             \n",
            "\n",
            "  linear_b      greek\n",
            "0    ğ€€ğ€ğ€ªğ€¦ğ€²  Î±ÎµÎ»Î¹Ï€Î¿Ï„Î±Ï‚\n",
            "1     ğ€€ğ€ğ€´ğ€µ   Î±ÎµÎ¸Î¹ÏƒÏ„Î¿Ï‚\n",
            "2     ğ€€ğ€ğ€´ğ€µ      ÎµÎ¸Î¹Î¶Ï‰\n",
            "3     ğ€€ğ€…ğ€”ğ€ƒ     Î±Î´Î±Î¼Î±Î¿\n",
            "4     ğ€€ğ€…ğ€”ğ€ƒ     Î±Î´Î±Î¼Î±Ï‚ \n",
            "\n",
            "  linear_b     greek_original greek_cog_1 greek_cog_2\n",
            "0    ğ€€ğ€ğ€ªğ€¦ğ€²          Î±ÎµÎ»Î¹Ï€Î¿Ï„Î±Ï‚   Î±ÎµÎ»Î¹Ï€Î¿Ï„Î±Ï‚            \n",
            "1     ğ€€ğ€ğ€´ğ€µ                                           \n",
            "2     ğ€€ğ€…ğ€”ğ€ƒ      Î±Î´Î±Î¼Î±Î¿|Î±Î´Î±Î¼Î±Ï‚      Î±Î´Î±Î¼Î±Î¿      Î±Î´Î±Î¼Î±Ï‚\n",
            "3     ğ€€ğ€…ğ€•ğ€¸  Î±Î´Î±Î¼ÎµfÎµÎ¹Ï‚|Î±Î´Î±Î¼ÎµÏ…Ï‚   Î±Î´Î±Î¼ÎµfÎµÎ¹Ï‚     Î±Î´Î±Î¼ÎµÏ…Ï‚\n",
            "4    ğ€€ğ€…ğ€¨ğ€´ğ€          Î±Î´ÏÎ±ÏƒÏ„Î¹Î¿Ï‚   Î±Î´ÏÎ±ÏƒÏ„Î¹Î¿Ï‚            \n",
            "  linear_b      greek\n",
            "0    ğ€€ğ€ğ€ªğ€¦ğ€²  Î±ÎµÎ»Î¹Ï€Î¿Ï„Î±Ï‚\n",
            "1     ğ€€ğ€ğ€´ğ€µ           \n",
            "2     ğ€€ğ€…ğ€”ğ€ƒ     Î±Î´Î±Î¼Î±Î¿\n",
            "3     ğ€€ğ€…ğ€”ğ€ƒ     Î±Î´Î±Î¼Î±Ï‚\n",
            "4     ğ€€ğ€…ğ€•ğ€¸  Î±Î´Î±Î¼ÎµfÎµÎ¹Ï‚\n"
          ]
        }
      ],
      "source": [
        "# @title Modify the Data\n",
        "\n",
        "# LINEAR B COGNATES\n",
        "\n",
        "# Renaming the original greek column to track the original\n",
        "data_linearb.rename(columns={'greek': 'greek_original'}, inplace=True)\n",
        "# Split the 'Greek' col into 2\n",
        "split_columns = data_linearb['greek_original'].str.split('|', expand=True)\n",
        "\n",
        "# Assigning split cols\n",
        "data_linearb['greek_cog_1'] = split_columns[0]\n",
        "data_linearb['greek_cog_2'] = split_columns[1].fillna('')\n",
        "\n",
        "\n",
        "# LINEAR B NAMES\n",
        "\n",
        "data_linearb_names.rename(columns={'greek': 'greek_original'}, inplace=True)\n",
        "# Split the 'Greek' col into 2\n",
        "split_columns = data_linearb_names['greek_original'].str.split('|', expand=True)\n",
        "\n",
        "# Assigning split cols\n",
        "data_linearb_names['greek_cog_1'] = split_columns[0]\n",
        "data_linearb_names['greek_cog_2'] = split_columns[1].fillna('')\n",
        "\n",
        "# Replace all _ with blank space\n",
        "data_linearb_names.replace('_', '', inplace=True)\n",
        "\n",
        "assert(len(data_linearb)==len(data_linearb_names))\n",
        "data_linearb_split=[]\n",
        "data_linearb_names_split=[]\n",
        "for i in range(len(data_linearb)):\n",
        "    #fill linear B\n",
        "    temp=[data_linearb[\"linear_b\"].iloc[i],data_linearb[\"greek_cog_1\"].iloc[i]]\n",
        "    data_linearb_split.append(temp)\n",
        "    if data_linearb[\"greek_cog_2\"].iloc[i]!=\"\":\n",
        "        data_linearb_split.append([data_linearb[\"linear_b\"].iloc[i],data_linearb[\"greek_cog_2\"].iloc[i]])\n",
        "\n",
        "    #fill linear B names\n",
        "    temp=[data_linearb_names[\"linear_b\"].iloc[i],data_linearb_names[\"greek_cog_1\"].iloc[i]]\n",
        "    data_linearb_names_split.append(temp)\n",
        "    if data_linearb_names[\"greek_cog_2\"].iloc[i]!=\"\":\n",
        "        data_linearb_names_split.append([data_linearb_names[\"linear_b\"].iloc[i],data_linearb_names[\"greek_cog_2\"].iloc[i]])\n",
        "data_linearb_split=pd.DataFrame(data_linearb_split,columns=[\"linear_b\",\"greek\"])\n",
        "data_linearb_names_split=pd.DataFrame(data_linearb_names_split,columns=[\"linear_b\",\"greek\"])\n",
        "# Display first few rows\n",
        "print(data_linearb.head(),'\\n')\n",
        "print(data_linearb_split.head(),'\\n')\n",
        "# print('\\n ------ LINEAR B NAMES -----\\n')\n",
        "print(data_linearb_names.head())\n",
        "print(data_linearb_names_split.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6UvDXgERS03M",
        "outputId": "532648f0-a511-442d-8eb7-84cd3f65a77d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "585\n",
            "464\n"
          ]
        }
      ],
      "source": [
        "#only need to split names into train and test for now,\n",
        "#since the names has several hundred blanks while there are no blanks in the ovr data\n",
        "data_linearb_names_train=data_linearb_names_split[data_linearb_names_split[\"greek\"]!=\"\"]\n",
        "data_linearb_names_test=data_linearb_names_split[data_linearb_names_split[\"greek\"]==\"\"]\n",
        "print(len(data_linearb_names_train))\n",
        "print(len(data_linearb_names_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gn1-3Fg_Xyws"
      },
      "source": [
        "## EXPLORATORY DATA ANALYSIS\n",
        "\n",
        "Analyze the dataset features.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DlKUCwmpX5zR",
        "outputId": "b2a34baa-18a4-4f21-dd4f-c838c4de7690"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "----- DESCRIBING THE COGNATE DATA: -----\n",
            "\n",
            "       linear_b greek_original greek_cog_1 greek_cog_2\n",
            "count       919            919         919         919\n",
            "unique      919            918         918         388\n",
            "top       ğ€€ğ€ğ€ªğ€¦ğ€²        ÎµÏ€Î¹|Î¿Ï€Î¹         ÎµÏ€Î¹            \n",
            "freq          1              2           2         528\n",
            "\n",
            "----- INFO: -----\n",
            "\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 919 entries, 0 to 918\n",
            "Data columns (total 4 columns):\n",
            " #   Column          Non-Null Count  Dtype \n",
            "---  ------          --------------  ----- \n",
            " 0   linear_b        919 non-null    object\n",
            " 1   greek_original  919 non-null    object\n",
            " 2   greek_cog_1     919 non-null    object\n",
            " 3   greek_cog_2     919 non-null    object\n",
            "dtypes: object(4)\n",
            "memory usage: 28.8+ KB\n",
            "None\n",
            "\n",
            "----- CHECKING FOR MISSING VALUES: -----\n",
            "\n",
            "linear_b          0\n",
            "greek_original    0\n",
            "greek_cog_1       0\n",
            "greek_cog_2       0\n",
            "dtype: int64\n",
            "\n",
            "----- CHECKING UNIQUE VALUES: -----\n",
            "\n",
            "linear_b\n",
            "ğ€€ğ€ğ€ªğ€¦ğ€²     1\n",
            "ğ€Ÿğ€©ğ€„ğ€«ğ€™ğ€†    1\n",
            "ğ€Ÿğ€©ğ€ğ€„      1\n",
            "ğ€Ÿğ€©ğ€¦ğ€²      1\n",
            "ğ€Ÿğ€ªğ€•ğ€†      1\n",
            "         ..\n",
            "ğ€„ğŠ        1\n",
            "ğ€…ğ€‚ğ€¦ğ€²      1\n",
            "ğ€…ğ€‚ğ€²ğ€¨ğ€«     1\n",
            "ğ€…ğ€…ğ€©ğ€ğ€†     1\n",
            "ğ‡ğ€œ        1\n",
            "Name: count, Length: 919, dtype: int64\n",
            "greek_original\n",
            "ÎµÏ€Î¹|Î¿Ï€Î¹                  2\n",
            "Î±ÎµÎ»Î¹Ï€Î¿Ï„Î±Ï‚                1\n",
            "Ï€Î¹Ï€Î·Ï‚                    1\n",
            "Ï€ÏÎµÏƒÏ€Î¿Ï„Î±Ï‚                1\n",
            "Ï€ÎµÏÎ¹Î¼Î·Î´Î·Ï‚                1\n",
            "                        ..\n",
            "Î´Î±Î¹Ï€Î¿Î½Ï„Î±Ï‚                1\n",
            "Î´Î±Î¹Ï„ÏÎ±ÏÎ¿Ï‚                1\n",
            "Î´Î±Î´Î±Î»ÎµÎ¹Î¿Î½|Î´Î±Î´Î±Î»ÎµÎ¹Î¿Î½Î´Îµ    1\n",
            "Î´Î±Î¹Î±ÏÎ¿Ï‚                  1\n",
            "Ï†Ï„ÎµÎ½Î¿Î¹                   1\n",
            "Name: count, Length: 918, dtype: int64\n",
            "greek_cog_1\n",
            "ÎµÏ€Î¹          2\n",
            "Î±ÎµÎ»Î¹Ï€Î¿Ï„Î±Ï‚    1\n",
            "Ï€Î¹Ï€Î·Ï‚        1\n",
            "Ï€ÏÎµÏƒÏ€Î¿Ï„Î±Ï‚    1\n",
            "Ï€ÎµÏÎ¹Î¼Î·Î´Î·Ï‚    1\n",
            "            ..\n",
            "Î´Î±Î¹Ï€Î¿Î½Ï„Î±Ï‚    1\n",
            "Î´Î±Î¹Ï„ÏÎ±ÏÎ¿Ï‚    1\n",
            "Î´Î±Î´Î±Î»ÎµÎ¹Î¿Î½    1\n",
            "Î´Î±Î¹Î±ÏÎ¿Ï‚      1\n",
            "Ï†Ï„ÎµÎ½Î¿Î¹       1\n",
            "Name: count, Length: 918, dtype: int64\n",
            "greek_cog_2\n",
            "              528\n",
            "Î´Î¹Î´Ï‰            2\n",
            "ÎºÎ¿Ï…ÏÎ·Î¹Î±         2\n",
            "Î¿Ï€Î¹             2\n",
            "Î¿ÏÏ‰             2\n",
            "             ... \n",
            "Î¿Î´ÏÏ…Ï‚           1\n",
            "Î¿Ï…Ï„Îµ            1\n",
            "Î¿Ï…Î´Î¹Î´Î¿Î½Ï„Î¿Î¹      1\n",
            "Î¹Î¸ÎµÎ¹Î±Ï‰Î½         1\n",
            "Î´Ï…fÎ¿            1\n",
            "Name: count, Length: 388, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Basic statistics and exploration\n",
        "\n",
        "print('\\n----- DESCRIBING THE COGNATE DATA: -----\\n')\n",
        "print(data_linearb.describe())\n",
        "\n",
        "print('\\n----- INFO: -----\\n')\n",
        "print(data_linearb.info())\n",
        "\n",
        "# Check for missing values\n",
        "print('\\n----- CHECKING FOR MISSING VALUES: -----\\n')\n",
        "print(data_linearb.isnull().sum())\n",
        "\n",
        "# Explore unique values and frequency distribution\n",
        "print('\\n----- CHECKING UNIQUE VALUES: -----\\n')\n",
        "print(data_linearb['linear_b'].value_counts())\n",
        "print(data_linearb['greek_original'].value_counts())\n",
        "print(data_linearb['greek_cog_1'].value_counts())\n",
        "print(data_linearb['greek_cog_2'].value_counts())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EOtKu8kMS03N",
        "outputId": "e35b3c79-63f0-48be-ad06-50ff082cdbef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "----- DESCRIBING THE NAMES DATA: -----\n",
            "\n",
            "       linear_b greek_original greek_cog_1 greek_cog_2\n",
            "count       919            919         919         919\n",
            "unique      919            456         456         131\n",
            "top       ğ€€ğ€ğ€ªğ€¦ğ€²                                       \n",
            "freq          1            464         464         789\n",
            "\n",
            "----- INFO: -----\n",
            "\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 919 entries, 0 to 918\n",
            "Data columns (total 4 columns):\n",
            " #   Column          Non-Null Count  Dtype \n",
            "---  ------          --------------  ----- \n",
            " 0   linear_b        919 non-null    object\n",
            " 1   greek_original  919 non-null    object\n",
            " 2   greek_cog_1     919 non-null    object\n",
            " 3   greek_cog_2     919 non-null    object\n",
            "dtypes: object(4)\n",
            "memory usage: 28.8+ KB\n",
            "None\n",
            "\n",
            "----- CHECKING FOR MISSING VALUES: -----\n",
            "\n",
            "linear_b          0\n",
            "greek_original    0\n",
            "greek_cog_1       0\n",
            "greek_cog_2       0\n",
            "dtype: int64\n",
            "\n",
            "----- CHECKING UNIQUE VALUES: -----\n",
            "\n",
            "linear_b\n",
            "ğ€€ğ€ğ€ªğ€¦ğ€²     1\n",
            "ğ€Ÿğ€©ğ€„ğ€«ğ€™ğ€†    1\n",
            "ğ€Ÿğ€©ğ€ğ€„      1\n",
            "ğ€Ÿğ€©ğ€¦ğ€²      1\n",
            "ğ€Ÿğ€ªğ€•ğ€†      1\n",
            "         ..\n",
            "ğ€„ğŠ        1\n",
            "ğ€…ğ€‚ğ€¦ğ€²      1\n",
            "ğ€…ğ€‚ğ€²ğ€¨ğ€«     1\n",
            "ğ€…ğ€…ğ€©ğ€ğ€†     1\n",
            "ğ‡ğ€œ        1\n",
            "Name: count, Length: 919, dtype: int64\n",
            "greek_original\n",
            "                464\n",
            "Ï€ÎµÏÎ¹Î¸Î¿fÎ¿Ï‚         1\n",
            "Ï€Î¿Î»Î¹fÎ¿Ï‚           1\n",
            "Ï€Î¿ÏÏ†Ï…ÏÎ¹Ï‰Î½         1\n",
            "Ï€Î¿Î´Î±ÏÎ³Î¿Ï‚          1\n",
            "               ... \n",
            "Ï…Î»ÎµÏ…Ï‚             1\n",
            "Ï…Î»Î±Î¼Î½Î¿Ï‚           1\n",
            "Ï…Î»Î±Î¹Î¿Ï‚            1\n",
            "Î¿fÎ¹Ï„Î½Î¿Ï‚           1\n",
            "Ï†Ï…Î»Î¹Î±Ï‚Î±Î³ÏÎµÏ…Ï‚      1\n",
            "Name: count, Length: 456, dtype: int64\n",
            "greek_cog_1\n",
            "                464\n",
            "Ï€ÎµÏÎ¹Î¸Î¿fÎ¿Ï‚         1\n",
            "Ï€Î¿Î»Î¹fÎ¿Ï‚           1\n",
            "Ï€Î¿ÏÏ†Ï…ÏÎ¹Ï‰Î½         1\n",
            "Ï€Î¿Î´Î±ÏÎ³Î¿Ï‚          1\n",
            "               ... \n",
            "Ï…Î»ÎµÏ…Ï‚             1\n",
            "Ï…Î»Î±Î¼Î½Î¿Ï‚           1\n",
            "Ï…Î»Î±Î¹Î¿Ï‚            1\n",
            "Î¿fÎ¹Ï„Î½Î¿Ï‚           1\n",
            "Ï†Ï…Î»Î¹Î±Ï‚Î±Î³ÏÎµÏ…Ï‚      1\n",
            "Name: count, Length: 456, dtype: int64\n",
            "greek_cog_2\n",
            "              789\n",
            "Ï€ÎµÏ€Î¹Î¸Î¼ÎµÎ½Î¿Ï‚      1\n",
            "ÏƒÏ†Î±Î³Î¹Î±Î½Î¹Î¿Î¹      1\n",
            "Ï†Î±ÏƒÎ³Î¹Î±Î½Î±Î¹       1\n",
            "Ï€Î±Î¹Î±fÏ‰Î½         1\n",
            "             ... \n",
            "ÎµÎ»ÎµÏ…Î¸ÎµÏÎµÎ¹       1\n",
            "ÎµÎ»Î¿Ï‚            1\n",
            "ÎµÏÎ±Î¸ÏÎµfÎµÎ¹       1\n",
            "ÎµÎ»Î±Ï„Î¿Î½Î´Îµ        1\n",
            "Î±Ï…Î³ÎµÏ…Ï‚          1\n",
            "Name: count, Length: 131, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print('\\n----- DESCRIBING THE NAMES DATA: -----\\n')\n",
        "print(data_linearb_names.describe())\n",
        "\n",
        "print('\\n----- INFO: -----\\n')\n",
        "print(data_linearb_names.info())\n",
        "\n",
        "# Check for missing values\n",
        "print('\\n----- CHECKING FOR MISSING VALUES: -----\\n')\n",
        "print(data_linearb_names.isnull().sum())\n",
        "\n",
        "# Explore unique values and frequency distribution\n",
        "print('\\n----- CHECKING UNIQUE VALUES: -----\\n')\n",
        "print(data_linearb_names['linear_b'].value_counts())\n",
        "print(data_linearb_names['greek_original'].value_counts())\n",
        "print(data_linearb_names['greek_cog_1'].value_counts())\n",
        "print(data_linearb_names['greek_cog_2'].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFOJEmRTS03O"
      },
      "source": [
        "## SPLITTING & TOKENIZATION\n",
        "\n",
        "- Breakdown the words into characters\n",
        "- ???\n",
        "- Split the data into test train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ChnA4BoES03O"
      },
      "outputs": [],
      "source": [
        "# @title: Splitting & tokenizing the data\n",
        "\n",
        "\n",
        "# SPLIT THE DATA HERE... BUT HOW? WHAT ARE THE LABELS?\n",
        "\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Tokenize the data\n",
        "data_linearb_names_train['linear_b_tokens'] = data_linearb_names_train['linear_b'].apply(lambda x: tokenizer.encode(x, add_special_tokens=True))\n",
        "data_linearb_names_train['greek_tokens'] = data_linearb_names_train['greek'].apply(lambda x: tokenizer.encode(x, add_special_tokens=True))\n",
        "data_linearb_names_test['linear_b_tokens'] = data_linearb_names_test['linear_b'].apply(lambda x: tokenizer.encode(x, add_special_tokens=True))\n",
        "data_linearb['greek_cog_1_tokens'] = data_linearb['greek_cog_1'].apply(lambda x: tokenizer.encode(x, add_special_tokens=True))\n",
        "data_linearb['greek_cog_2_tokens'] = data_linearb['greek_cog_2'].apply(lambda x: tokenizer.encode(x, add_special_tokens=True) if x else [])\n",
        "\n",
        "\n",
        "# NEED TO TOKENIZE NAMES AND OTHER DATASETS THAT ARE LOADED HERE\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hcpc27jJX7JU"
      },
      "source": [
        "## MODEL ARCHITECTURE\n",
        "\n",
        "- Identify baseline model\n",
        "- Test other Seq2seq models\n",
        "  - Transformer model - our own?\n",
        "  - Or can we modify BERT/another model and train it too?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2jXBtljgS03P"
      },
      "source": [
        "### Loading the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sUxpeJLjX89Y"
      },
      "outputs": [],
      "source": [
        "# Loading BERT\n",
        "config = BertConfig.from_pretrained('bert-base-uncased', output_attentions=True)\n",
        "bert_model = BertModel(config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYBwnmy1S03P"
      },
      "source": [
        "### Building the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "03H5YWQ3S03Q"
      },
      "outputs": [],
      "source": [
        "# Building the COgnate model (sample skeleton)\n",
        "\n",
        "class CognatePredictionModel(nn.Module):\n",
        "    def __init__(self, bert_model):\n",
        "        super(CognatePredictionModel, self).__init__()\n",
        "        self.bert = bert_model\n",
        "\n",
        "        # BERT outputs a 768-d vector\n",
        "        bert_output_size = 768\n",
        "\n",
        "        # Additional fully connected layers\n",
        "        self.fc1 = nn.Linear(bert_output_size * 2, 512)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(512, 256)\n",
        "        # Output layer for binary classification\n",
        "        self.fc3 = nn.Linear(256, 1)\n",
        "\n",
        "    def forward(self, linear_b_tokens, greek_tokens):\n",
        "        # Pass input through BERT, take pooled output\n",
        "        outputs_linear_b = self.bert(linear_b_tokens)[1]\n",
        "        outputs_greek = self.bert(greek_tokens)[1]\n",
        "\n",
        "        # Concatenate the outputs\n",
        "        combined = torch.cat((outputs_linear_b, outputs_greek), 1)\n",
        "\n",
        "        # Pass through additional layers; placeholders\n",
        "        x = self.fc1(combined)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc3(x)\n",
        "\n",
        "        #print x\n",
        "        # Should be tensor with logits\n",
        "\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHW72bz1S03Q"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_pjRsqtmZUfW"
      },
      "source": [
        "## TRAINING\n",
        "\n",
        "- Train the model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unique_greek_tokens = set()\n",
        "\n",
        "for tokens in data_linearb_names_train['greek']:\n",
        "    unique_greek_tokens.update(tokens.split('|'))\n",
        "\n",
        "for tokens in data_linearb_names_test['greek']:\n",
        "    unique_greek_tokens.update(tokens.split('|'))\n",
        "\n",
        "token_to_id = {token: idx for idx, token in enumerate(unique_greek_tokens)}"
      ],
      "metadata": {
        "id": "Up1TAf_STKbE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SLn_2sABZZ7j"
      },
      "outputs": [],
      "source": [
        "class CognateDataset(Dataset):\n",
        "    def __init__(self, linear_b_tokens, greek_tokens, token_to_id, default_id=0):\n",
        "        self.linear_b_tokens = linear_b_tokens\n",
        "        self.greek_tokens = greek_tokens\n",
        "        self.token_to_id = token_to_id\n",
        "        self.default_id = default_id\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.linear_b_tokens)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        linear_b_token_tensor = torch.tensor(self.linear_b_tokens[idx], dtype=torch.long)\n",
        "        greek_token_tensor = torch.tensor(self.greek_tokens[idx], dtype=torch.long)\n",
        "\n",
        "        return {\n",
        "            'linear_b_tokens': linear_b_token_tensor,\n",
        "            'greek_tokens': greek_token_tensor\n",
        "        }\n",
        "\n",
        "train_dataset = CognateDataset(\n",
        "    data_linearb_names_train['linear_b_tokens'].tolist(),\n",
        "    data_linearb_names_train['greek_tokens'].tolist(),\n",
        "    token_to_id,\n",
        "    default_id=0\n",
        ")\n",
        "\n",
        "test_dataset = CognateDataset(\n",
        "    data_linearb_names_test['linear_b_tokens'].tolist(),\n",
        "    # For test data, you might not have labels or might handle them differently\n",
        "    [0] * len(data_linearb_names_test),  # Placeholder if you don't have labels\n",
        "    token_to_id,\n",
        "    default_id=0\n",
        ")\n",
        "\n",
        "def collate_fn(batch):\n",
        "    linear_b_tokens = [item['linear_b_tokens'] for item in batch]\n",
        "    greek_tokens = [item['greek_tokens'] for item in batch]\n",
        "\n",
        "    # Pad sequences\n",
        "    linear_b_tokens_padded = pad_sequence(linear_b_tokens, batch_first=True, padding_value=tokenizer.pad_token_id)\n",
        "    greek_tokens_padded = pad_sequence(greek_tokens, batch_first=True, padding_value=tokenizer.pad_token_id)\n",
        "\n",
        "    return {\n",
        "        'linear_b_tokens': linear_b_tokens_padded,\n",
        "        'greek_tokens': greek_tokens_padded\n",
        "    }\n",
        "\n",
        "data_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model\n",
        "\n",
        "model = CognatePredictionModel(bert_model)\n",
        "loss_function = nn.BCEWithLogitsLoss()\n",
        "optimizer = Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "\n",
        "num_epochs = 5\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    correct_predictions = 0\n",
        "    total_predictions = 0\n",
        "\n",
        "    for batch in data_loader:\n",
        "        linear_b_tokens = batch['linear_b_tokens']\n",
        "        greek_tokens = batch['greek_tokens']\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(linear_b_tokens, greek_tokens)\n",
        "        outputs = outputs.squeeze()\n",
        "\n",
        "        loss = loss_function(outputs, greek_tokens.float())\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        predicted_labels = (outputs > 0).float()\n",
        "        correct_predictions += (predicted_labels == greek_tokens).sum().item()\n",
        "        total_predictions += greek_tokens.numel()\n",
        "\n",
        "    avg_loss = total_loss / len(data_loader)\n",
        "    accuracy = correct_predictions / total_predictions\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}, Accuracy: {accuracy:.4f}\")"
      ],
      "metadata": {
        "id": "ZHyiuSm8Tpr9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KCwEcUksZCCv"
      },
      "source": [
        "## EVALUATION\n",
        "\n",
        "- The primary goal metric is accuracy as compared to NeuroDecipher"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4fs1bKF0ZJJp"
      },
      "outputs": [],
      "source": [
        "# Evaluation code\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (test)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}